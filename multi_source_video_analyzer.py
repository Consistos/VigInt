#!/usr/bin/env python3
"""
Multi-Source Video Analyzer for Vigint
Handles simultaneous analysis of multiple video sources with aggregation
"""

import cv2
import time
import logging
import threading
import base64
import os
import tempfile
import numpy as np
from datetime import datetime
from collections import deque
from concurrent.futures import ThreadPoolExecutor, as_completed
import google.generativeai as genai
from config import config
from alerts import send_security_alert_with_video

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class VideoSource:
    """Represents a single video source"""
    
    def __init__(self, source_id, rtsp_url, name=None):
        self.source_id = source_id
        self.rtsp_url = rtsp_url
        self.name = name or f"Camera_{source_id}"
        self.cap = None
        self.frame_count = 0
        self.last_frame = None
        self.last_frame_time = 0
        self.running = False
        self.thread = None
        
        # Frame buffer for video creation (keep last 10 seconds at 25fps = 250 frames)
        self.frame_buffer = deque(maxlen=250)
        self.buffer_fps = 25
    
    def start(self):
        """Start capturing from this video source"""
        logger.info(f"Starting video source {self.source_id}: {self.name}")
        
        self.cap = cv2.VideoCapture(self.rtsp_url)
        if not self.cap.isOpened():
            logger.error(f"Failed to open video source {self.source_id}: {self.rtsp_url}")
            return False
        
        self.running = True
        self.thread = threading.Thread(target=self._capture_loop, daemon=True)
        self.thread.start()
        
        logger.info(f"Video source {self.source_id} started successfully")
        return True
    
    def stop(self):
        """Stop capturing from this video source"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=5)
        if self.cap:
            self.cap.release()
        logger.info(f"Video source {self.source_id} stopped")
    
    def _capture_loop(self):
        """Main capture loop for this video source"""
        while self.running:
            try:
                ret, frame = self.cap.read()
                
                if not ret:
                    # Check if this is a video file that has ended
                    if hasattr(self.cap, 'get') and self.cap.get(cv2.CAP_PROP_FRAME_COUNT) > 0:
                        # Video file ended, restart from beginning
                        logger.info(f"Video file ended for source {self.source_id}, restarting...")
                        self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                        continue
                    else:
                        logger.warning(f"Failed to read frame from source {self.source_id}")
                        time.sleep(1)
                        continue
                
                self.frame_count += 1
                self.last_frame = frame.copy()
                self.last_frame_time = time.time()
                
                # Add frame to buffer
                self._add_frame_to_buffer(frame.copy())
                
                # Small delay to prevent overwhelming the system
                time.sleep(0.04)  # ~25 FPS
                
            except Exception as e:
                logger.error(f"Error in capture loop for source {self.source_id}: {e}")
                time.sleep(1)
    
    def _add_frame_to_buffer(self, frame):
        """Add frame to buffer for video creation"""
        try:
            # Ensure frame is valid and has content
            if frame is None or frame.size == 0:
                logger.warning(f"Invalid frame for source {self.source_id}, skipping")
                return
            
            # Convert frame to base64 for storage with good quality
            encode_params = [cv2.IMWRITE_JPEG_QUALITY, 90]
            _, buffer_img = cv2.imencode('.jpg', frame, encode_params)
            frame_base64 = base64.b64encode(buffer_img).decode('utf-8')
            
            # Create detailed frame info with timestamp
            frame_info = {
                'frame_data': frame_base64,
                'frame_count': self.frame_count,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3],  # Include milliseconds
                'source_id': self.source_id,
                'source_name': self.name,
                'frame_size': frame.shape,
                'capture_time': time.time()
            }
            
            self.frame_buffer.append(frame_info)
            
        except Exception as e:
            logger.error(f"Error adding frame to buffer for source {self.source_id}: {e}")
    
    def get_recent_frames(self, duration_seconds=5):
        """Get recent frames from buffer for video creation"""
        try:
            # Calculate number of frames needed
            frames_needed = duration_seconds * self.buffer_fps
            
            # Get the most recent frames
            if len(self.frame_buffer) >= frames_needed:
                return list(self.frame_buffer)[-frames_needed:]
            else:
                return list(self.frame_buffer)
                
        except Exception as e:
            logger.error(f"Error getting recent frames for source {self.source_id}: {e}")
            return []
    
    def get_current_frame(self):
        """Get the most recent frame"""
        return self.last_frame if self.last_frame is not None else None
    
    def is_active(self):
        """Check if this source is actively receiving frames"""
        if not self.running:
            return False
        
        # Consider active if we received a frame in the last 5 seconds
        return time.time() - self.last_frame_time < 5.0


class MultiSourceVideoAnalyzer:
    """Handles simultaneous analysis of multiple video sources with aggregation"""
    
    def __init__(self, api_key=None):
        # Configure Gemini AI
        self.gemini_api_key = api_key or os.getenv('GOOGLE_API_KEY')
        if self.gemini_api_key:
            genai.configure(
                api_key=self.gemini_api_key,
                transport='rest'
            )
            self.model = genai.GenerativeModel('gemini-1.5-flash')
            logger.info("Gemini AI configured successfully")
        else:
            logger.error("Gemini API key not found in environment variables")
            self.model = None
        
        self.video_sources = {}
        self.analysis_interval = 10  # Analyze every 10 seconds
        self.last_analysis_time = 0
        self.running = False
        self.analysis_thread = None
        
        # Thread pool for parallel analysis
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    def add_video_source(self, source_id, rtsp_url, name=None):
        """Add a video source to be analyzed"""
        if source_id in self.video_sources:
            logger.warning(f"Video source {source_id} already exists, replacing...")
            self.remove_video_source(source_id)
        
        source = VideoSource(source_id, rtsp_url, name)
        self.video_sources[source_id] = source
        
        # Start the source if analyzer is running
        if self.running:
            source.start()
        
        logger.info(f"Added video source {source_id}: {name or rtsp_url}")
        return True
    
    def remove_video_source(self, source_id):
        """Remove a video source"""
        if source_id in self.video_sources:
            self.video_sources[source_id].stop()
            del self.video_sources[source_id]
            logger.info(f"Removed video source {source_id}")
            return True
        return False
    
    def start_analysis(self):
        """Start analyzing all video sources"""
        if self.running:
            logger.warning("Analysis already running")
            return False
        
        if not self.video_sources:
            logger.error("No video sources configured")
            return False
        
        logger.info(f"Starting multi-source video analysis with {len(self.video_sources)} sources")
        
        # Start all video sources
        for source in self.video_sources.values():
            source.start()
        
        # Wait a moment for sources to initialize
        time.sleep(3)
        
        self.running = True
        self.analysis_thread = threading.Thread(target=self._analysis_loop, daemon=True)
        self.analysis_thread.start()
        
        logger.info("Multi-source video analysis started")
        return True
    
    def stop_analysis(self):
        """Stop analyzing all video sources"""
        if not self.running:
            return
        
        logger.info("Stopping multi-source video analysis")
        self.running = False
        
        # Stop all video sources
        for source in self.video_sources.values():
            source.stop()
        
        # Wait for analysis thread to finish
        if self.analysis_thread:
            self.analysis_thread.join(timeout=10)
        
        # Shutdown executor
        self.executor.shutdown(wait=True)
        
        logger.info("Multi-source video analysis stopped")
    
    def _analysis_loop(self):
        """Main analysis loop"""
        while self.running:
            try:
                current_time = time.time()
                
                if current_time - self.last_analysis_time >= self.analysis_interval:
                    self.last_analysis_time = current_time
                    
                    # Get active sources
                    active_sources = [s for s in self.video_sources.values() if s.is_active()]
                    
                    if active_sources:
                        logger.info(f"Analyzing {len(active_sources)} active video sources")
                        self._analyze_sources(active_sources)
                    else:
                        logger.warning("No active video sources for analysis")
                
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"Error in analysis loop: {e}")
                time.sleep(5)
    
    def _analyze_sources(self, active_sources):
        """Analyze active video sources with aggregation logic"""
        try:
            num_sources = len(active_sources)
            
            if num_sources >= 4:
                # Group sources by 4 for aggregated analysis
                groups = []
                individual_sources = []
                
                # Create groups of 4
                for i in range(0, num_sources, 4):
                    group = active_sources[i:i+4]
                    if len(group) == 4:
                        groups.append(group)
                    else:
                        # Remainder sources stay individual
                        individual_sources.extend(group)
                
                logger.info(f"Created {len(groups)} groups of 4 sources, {len(individual_sources)} individual sources")
                
                # Analyze groups in parallel
                futures = []
                
                # Submit aggregated analysis tasks
                for i, group in enumerate(groups):
                    future = self.executor.submit(self._analyze_aggregated_group, group, f"group_{i+1}")
                    futures.append(future)
                
                # Submit individual analysis tasks
                for source in individual_sources:
                    future = self.executor.submit(self._analyze_individual_source, source)
                    futures.append(future)
                
                # Wait for all analyses to complete
                for future in as_completed(futures, timeout=60):
                    try:
                        result = future.result()
                        if result and result.get('incident_detected', False):
                            self._handle_security_incident(result)
                    except Exception as e:
                        logger.error(f"Error in parallel analysis: {e}")
            
            else:
                # Analyze all sources individually
                logger.info(f"Analyzing {num_sources} sources individually")
                
                futures = []
                for source in active_sources:
                    future = self.executor.submit(self._analyze_individual_source, source)
                    futures.append(future)
                
                # Wait for all analyses to complete
                for future in as_completed(futures, timeout=60):
                    try:
                        result = future.result()
                        if result and result.get('incident_detected', False):
                            self._handle_security_incident(result)
                    except Exception as e:
                        logger.error(f"Error in individual analysis: {e}")
        
        except Exception as e:
            logger.error(f"Error in source analysis: {e}")
    
    def _analyze_individual_source(self, source):
        """Analyze a single video source"""
        try:
            frame = source.get_current_frame()
            if frame is None:
                return None
            
            logger.info(f"Analyzing individual source: {source.name}")
            
            # Convert frame to base64 for Gemini API
            _, buffer_img = cv2.imencode('.jpg', frame)
            frame_base64 = base64.b64encode(buffer_img).decode('utf-8')
            
            # Prepare the prompt
            prompt = f"""
            Analyze the provided video frame from camera "{source.name}" for security incidents in a retail environment, with special focus on shoplifting behavior. Pay particular attention to:
            1. Customers taking items and concealing them (in pockets, bags, clothing)
            2. Unusual handling of merchandise (checking for security tags, looking around suspiciously)
            3. Taking items without paying
            4. Groups working together to distract staff while items are taken
            5. Removing packaging or security devices
            6. Unusual movements around high-value items
            7. Signs of nervousness or anxiety while handling merchandise
            
            Your analysis must be thorough and should err on the side of detecting potential security incidents rather than missing them.
            
            Return ONLY the JSON object without markdown formatting, code blocks, or additional text.
            If no incidents are detected, return the JSON with incident_detected set to false.
            
            Your response must be a valid JSON object with the following structure:
            {{"incident_detected": boolean,  // true if an incident is detected, false otherwise
            "incident_type": string,     // Describe the type of incident (e.g.: shoplifting, theft, vandalism)
            "confidence": float,         // confidence level between 0.0 and 1.0
            "description": string,       // brief description of what you see
            "analysis": string,          // detailed analysis of the video content
            "camera_name": string}}      // camera name for reference
            
            Answer in French.
            """
            
            # Send to Gemini for analysis
            response = self.model.generate_content([
                prompt,
                {"mime_type": "image/jpeg", "data": frame_base64}
            ])
            
            # Parse JSON response
            analysis_result = self._parse_analysis_response(response.text, source)
            
            if analysis_result:
                logger.info(f"Individual analysis completed for {source.name}: incident_detected={analysis_result.get('incident_detected', False)}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"Error analyzing individual source {source.source_id}: {e}")
            return None
    
    def _analyze_aggregated_group(self, group_sources, group_name):
        """Analyze a group of 4 video sources as an aggregated view"""
        try:
            logger.info(f"Analyzing aggregated group: {group_name} with {len(group_sources)} sources")
            
            # Get current frames from all sources in the group
            frames = []
            source_names = []
            
            for source in group_sources:
                frame = source.get_current_frame()
                if frame is not None:
                    frames.append(frame)
                    source_names.append(source.name)
            
            if not frames:
                logger.warning(f"No frames available for group {group_name}")
                return None
            
            # Create a composite image from the group frames
            composite_frame = self._create_composite_frame(frames, source_names)
            
            if composite_frame is None:
                logger.error(f"Failed to create composite frame for group {group_name}")
                return None
            
            # Convert composite frame to base64 for Gemini API
            _, buffer_img = cv2.imencode('.jpg', composite_frame)
            frame_base64 = base64.b64encode(buffer_img).decode('utf-8')
            
            # Prepare the prompt for aggregated analysis
            camera_list = ", ".join(source_names)
            prompt = f"""
            Analyze the provided composite video frame showing multiple camera views ({camera_list}) for security incidents in a retail environment. This is an aggregated view of {len(source_names)} cameras simultaneously.
            
            Pay particular attention to:
            1. Customers taking items and concealing them (in pockets, bags, clothing)
            2. Unusual handling of merchandise (checking for security tags, looking around suspiciously)
            3. Taking items without paying
            4. Groups working together to distract staff while items are taken
            5. Removing packaging or security devices
            6. Unusual movements around high-value items
            7. Signs of nervousness or anxiety while handling merchandise
            8. Coordinated suspicious activities across multiple camera views
            
            Since this is a multi-camera view, also look for:
            - Suspicious individuals moving between camera zones
            - Coordinated group activities across different areas
            - Patterns of behavior that span multiple camera views
            
            Your analysis must be thorough and should err on the side of detecting potential security incidents rather than missing them.
            
            Return ONLY the JSON object without markdown formatting, code blocks, or additional text.
            If no incidents are detected, return the JSON with incident_detected set to false.
            
            Your response must be a valid JSON object with the following structure:
            {{"incident_detected": boolean,  // true if an incident is detected, false otherwise
            "incident_type": string,     // Describe the type of incident (e.g.: shoplifting, theft, vandalism)
            "confidence": float,         // confidence level between 0.0 and 1.0
            "description": string,       // brief description of what you see
            "analysis": string,          // detailed analysis of the video content
            "camera_group": string,      // group identifier
            "cameras_involved": string}} // list of camera names in this group
            
            Answer in French.
            """
            
            # Send to Gemini for analysis
            response = self.model.generate_content([
                prompt,
                {"mime_type": "image/jpeg", "data": frame_base64}
            ])
            
            # Parse JSON response
            analysis_result = self._parse_analysis_response(response.text, None, group_name, source_names)
            
            if analysis_result:
                logger.info(f"Aggregated analysis completed for {group_name}: incident_detected={analysis_result.get('incident_detected', False)}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"Error analyzing aggregated group {group_name}: {e}")
            return None
    
    def _create_composite_frame(self, frames, source_names):
        """Create a composite frame from multiple source frames"""
        try:
            if not frames:
                return None
            
            # Resize all frames to a standard size
            target_width, target_height = 320, 240
            resized_frames = []
            
            for frame in frames:
                resized = cv2.resize(frame, (target_width, target_height))
                resized_frames.append(resized)
            
            # Create a 2x2 grid for 4 frames
            if len(resized_frames) >= 4:
                # Top row
                top_row = np.hstack([resized_frames[0], resized_frames[1]])
                # Bottom row
                bottom_row = np.hstack([resized_frames[2], resized_frames[3]])
                # Combine rows
                composite = np.vstack([top_row, bottom_row])
            elif len(resized_frames) == 3:
                # Top row with 2 frames
                top_row = np.hstack([resized_frames[0], resized_frames[1]])
                # Bottom row with 1 frame centered
                bottom_frame = resized_frames[2]
                padding = np.zeros((target_height, target_width, 3), dtype=np.uint8)
                bottom_row = np.hstack([padding, bottom_frame])
                composite = np.vstack([top_row, bottom_row])
            elif len(resized_frames) == 2:
                # Side by side
                composite = np.hstack([resized_frames[0], resized_frames[1]])
            else:
                # Single frame
                composite = resized_frames[0]
            
            # Add labels to identify each camera view
            for i, name in enumerate(source_names[:len(resized_frames)]):
                if len(resized_frames) >= 4:
                    # Calculate position for 2x2 grid
                    if i == 0:  # Top-left
                        x, y = 10, 25
                    elif i == 1:  # Top-right
                        x, y = target_width + 10, 25
                    elif i == 2:  # Bottom-left
                        x, y = 10, target_height + 25
                    else:  # Bottom-right
                        x, y = target_width + 10, target_height + 25
                else:
                    # Simple positioning for fewer frames
                    x, y = 10 + (i * target_width), 25
                
                cv2.putText(composite, name, (x, y), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            return composite
            
        except Exception as e:
            logger.error(f"Error creating composite frame: {e}")
            return None
    
    def _parse_analysis_response(self, response_text, source=None, group_name=None, source_names=None):
        """Parse the analysis response from Gemini"""
        try:
            import json
            
            response_text = response_text.strip()
            
            # Handle JSON wrapped in markdown code blocks
            if response_text.startswith('```json'):
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
                if start_idx != -1 and end_idx > start_idx:
                    response_text = response_text[start_idx:end_idx]
            
            analysis_json = json.loads(response_text)
            
            # Add metadata
            analysis_result = {
                'timestamp': datetime.now().isoformat(),
                'incident_detected': analysis_json.get('incident_detected', False),
                'incident_type': analysis_json.get('incident_type', ''),
                'confidence': analysis_json.get('confidence', 0.0),
                'description': analysis_json.get('description', ''),
                'analysis': analysis_json.get('analysis', response_text),
                'is_aggregated': group_name is not None
            }
            
            if source:
                analysis_result.update({
                    'source_id': source.source_id,
                    'source_name': source.name,
                    'frame_count': source.frame_count
                })
            
            if group_name:
                analysis_result.update({
                    'group_name': group_name,
                    'cameras_involved': source_names or [],
                    'num_cameras': len(source_names) if source_names else 0
                })
            
            return analysis_result
            
        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"Error parsing analysis response: {e}")
            # Fallback to text parsing
            response_text_lower = response_text.lower()
            incident_detected = 'incident_detected": true' in response_text_lower
            
            return {
                'timestamp': datetime.now().isoformat(),
                'incident_detected': incident_detected,
                'incident_type': 'Unknown',
                'confidence': 0.5,
                'description': 'Analysis parsing failed',
                'analysis': response_text,
                'is_aggregated': group_name is not None,
                'source_id': source.source_id if source else None,
                'source_name': source.name if source else None,
                'group_name': group_name,
                'cameras_involved': source_names or []
            }
    
    def _handle_security_incident(self, analysis_result):
        """Handle detected security incident"""
        try:
            logger.warning("üö® POTENTIAL SECURITY EVENT DETECTED!")
            logger.warning(f"Analysis: {analysis_result['analysis'][:200]}...")
            
            # Collect video frames from relevant sources
            video_frames = []
            
            if analysis_result.get('is_aggregated', False):
                # For aggregated analysis, collect frames from all involved cameras
                camera_names = analysis_result.get('cameras_involved', [])
                logger.info(f"Collecting video evidence from {len(camera_names)} cameras in group")
                
                for source in self.video_sources.values():
                    if source.name in camera_names:
                        frames = source.get_recent_frames(duration_seconds=8)
                        video_frames.extend(frames)
            else:
                # For individual analysis, collect frames from the specific source
                source_id = analysis_result.get('source_id')
                if source_id and source_id in self.video_sources:
                    frames = self.video_sources[source_id].get_recent_frames(duration_seconds=8)
                    video_frames.extend(frames)
            
            # Prepare incident data
            incident_data = {
                'risk_level': 'HIGH',
                'frame_count': analysis_result.get('frame_count', 0),
                'confidence': analysis_result.get('confidence', 0.0),
                'analysis': analysis_result.get('analysis', ''),
                'incident_type': analysis_result.get('incident_type', ''),
                'is_aggregated': analysis_result.get('is_aggregated', False),
                'cameras_involved': analysis_result.get('cameras_involved', [])
            }
            
            # Create alert message in French
            if analysis_result.get('is_aggregated', False):
                cameras_list = ', '.join(analysis_result.get('cameras_involved', []))
                message = f"""
INCIDENT DE S√âCURIT√â D√âTECT√â - ANALYSE MULTI-CAM√âRAS

Heure: {analysis_result['timestamp']}
Groupe de cam√©ras: {analysis_result.get('group_name', 'Inconnu')}
Cam√©ras impliqu√©es: {cameras_list}
Type d'incident: {analysis_result.get('incident_type', 'Non sp√©cifi√©')}
Niveau de confiance: {analysis_result.get('confidence', 0.0):.2f}

ANALYSE D√âTAILL√âE:
{analysis_result.get('analysis', 'Aucune analyse disponible')}

Cette alerte provient d'une analyse simultan√©e de plusieurs cam√©ras.
Veuillez examiner imm√©diatement les preuves vid√©o ci-jointes.
"""
            else:
                message = f"""
INCIDENT DE S√âCURIT√â D√âTECT√â

Heure: {analysis_result['timestamp']}
Cam√©ra: {analysis_result.get('source_name', 'Inconnue')}
Type d'incident: {analysis_result.get('incident_type', 'Non sp√©cifi√©')}
Niveau de confiance: {analysis_result.get('confidence', 0.0):.2f}

ANALYSE D√âTAILL√âE:
{analysis_result.get('analysis', 'Aucune analyse disponible')}

Ceci est une alerte automatique du syst√®me de s√©curit√© Vigint.
Veuillez examiner imm√©diatement les preuves vid√©o ci-jointes.
"""
            
            # Send alert with video evidence
            if video_frames:
                result = send_security_alert_with_video(message, video_frames, incident_data)
                if result.get('success', False):
                    logger.info("üö® MULTI-SOURCE SECURITY ALERT WITH VIDEO SENT!")
                else:
                    logger.error(f"Failed to send security alert: {result.get('error', 'Unknown error')}")
            else:
                logger.warning("No video frames available for alert")
            
        except Exception as e:
            logger.error(f"Error handling security incident: {e}")
    
    def get_status(self):
        """Get current status of all video sources"""
        status = {
            'running': self.running,
            'total_sources': len(self.video_sources),
            'active_sources': 0,
            'sources': {}
        }
        
        for source_id, source in self.video_sources.items():
            is_active = source.is_active()
            if is_active:
                status['active_sources'] += 1
            
            status['sources'][source_id] = {
                'name': source.name,
                'rtsp_url': source.rtsp_url,
                'active': is_active,
                'frame_count': source.frame_count,
                'last_frame_time': source.last_frame_time
            }
        
        return status


def main():
    """Main function for testing multi-source video analysis"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Multi-Source Video Analyzer')
    parser.add_argument('--sources', type=str, nargs='+', required=True,
                       help='RTSP URLs or video file paths')
    parser.add_argument('--names', type=str, nargs='*',
                       help='Names for the video sources')
    parser.add_argument('--interval', type=int, default=10,
                       help='Analysis interval in seconds (default: 10)')
    
    args = parser.parse_args()
    
    # Create analyzer
    analyzer = MultiSourceVideoAnalyzer()
    analyzer.analysis_interval = args.interval
    
    # Add video sources
    for i, source_url in enumerate(args.sources):
        source_id = f"source_{i+1}"
        source_name = args.names[i] if args.names and i < len(args.names) else f"Camera_{i+1}"
        analyzer.add_video_source(source_id, source_url, source_name)
    
    try:
        # Start analysis
        if analyzer.start_analysis():
            logger.info("Multi-source video analysis started. Press Ctrl+C to stop.")
            
            # Keep running and show status periodically
            while True:
                time.sleep(30)
                status = analyzer.get_status()
                logger.info(f"Status: {status['active_sources']}/{status['total_sources']} sources active")
        else:
            logger.error("Failed to start multi-source video analysis")
    
    except KeyboardInterrupt:
        logger.info("Shutting down multi-source video analyzer...")
    finally:
        analyzer.stop_analysis()


if __name__ == '__main__':
    main()